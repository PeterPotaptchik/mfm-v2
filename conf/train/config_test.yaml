defaults:
  - _self_
  - model: unet_cifar
  - dataset: cifar 
  - SI: linear

from_pretrained: false
resume_from_checkpoint: null
use_parametrization: false
compile: true

optimizer: "Adam"
seed: 42

loss:
  distillation_type: psd
  fm_loss_type: l2
  fm_adaptive_loss_p: 1.0
  fm_adaptive_loss_c: 0.01
  distillation_loss_type: adaptive
  distill_teacher_stop_grad: true
  distill_adaptive_loss_p: 0.5
  distill_adaptive_loss_c: 0.01
  explicit_v00_train: false
  distillation_weight: 1.0
  distill_fm_weight: 1.0
  fm_weight: 1.0
  distill_fm: false
  distill_fm_loss_type: l2
  model_guidance: false
  model_guidance_distill_base_prob: 0.2
  model_guidance_fm_base_prob: 0.2

weighting_model:
  _target_: distcfm.models.base_model.LossWeightingNetwork
  channels: 128
  clamp_min: -10.0
  clamp_max: 10.0


lr:
  val: 0.0003
  scheduler: constant 
  warmup_steps: 0 
  min_lr: 0.00001

trainer:
  num_train_steps: 100000 
  num_warmup_steps: 10000 
  num_model_guidance_steps: 10000
  num_no_posterior_steps: 0
  num_anneal_posterior_steps: 0
  t_cond_warmup_steps: 0
  t_cond_0_rate: 0.0
  t_cond_power: 1.0
  t_cond_anneal_end_step: 0
  anneal_end_step: 50000
  batch_size: 128 
  ema:
    decay: 0.999
  devices: "auto"
  log_every_n_steps: 25
  accumulate_grad_batches: 1
  precision: "bf16-mixed"
  gradient_clip_val: 25.0

sampling:
  every_n_steps: 10000
  n_unconditional_samples: 128 # total unconditional samples
  n_conditioning_samples: 32 # unique x_t
  n_samples_per_image: 4 #Â total_posterior_samples = n_conditioning_samples * n_samples_per_image
  max_batch_size: 32
  vae_batch_size: 32
  ode_sampler:
    steps: 100
  consistency_sampler:
    steps_to_test: 
    - 1
    - 4
  sample_shuffled_cfg_labels: true
  conditioning_times:
  - 0.00
  - 0.20
  - 0.40
  n_kernel_steps: 
  - 1
  - 4
  - 10
  kernel_cfg_scales: # for unconditional sampling (kernel)
  - 1.0
  - 1.5
  - 2.0
  kernel_churn: 0.0
  cfg_scales: # for posterior sampling (ODE/consistency) 
  - 1.0
  - 1.5
  - 2.0
  
wandb:
  project: ablations
  entity: distcfm
  name: default

data_dir: /vols/bitbucket/saravanan/distributional-mf/data
init_weights_ckpt: /n/netscratch/albergo_lab/Lab/ppotaptchik/distributional-mf/ckpt/dmf_xl_2_256.pt